{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_cifar_sample.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MksjtbHGec0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw6HmYo4ec0N",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Training an image Classifier with PyTorch\n",
        "\n",
        "This is it. You have seen how to define neural networks, compute loss and make updates to the weights of the network.\n",
        "\n",
        "We will be testing on the common CIFAR10 dataset. Fortunately, PyTorch provides the ``torchvision`` package that has loaders for common datasets such as this one.\n",
        "\n",
        "## CIFAR10\n",
        "The CIFAR-10 dataset contains 60k 32x32 color images (3 channels) in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6k images of each class. Furthermore the dataset is partitioned into 50k images for training and 10k for testing. \n",
        "\n",
        "## Training an image classifier\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "revwA0cM5sdn",
        "colab_type": "text"
      },
      "source": [
        "### 1. Loading and normalizing CIFAR10\n",
        "Using ``torchvision``, itâ€™s extremely easy to load CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM8YWwvOec0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao_0H2Lsec0P",
        "colab_type": "text"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "\n",
        "Torchvision also provides transform operations that allows us to normalize, modify and augment our datasets. Here we transform the images to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kJ9VXraec0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = trainset.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bciry-Y_ec0S",
        "colab_type": "text"
      },
      "source": [
        "Let's see some of the training images, just for the kicks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtDIeSh7ec0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]}' for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWblxoWlec0V",
        "colab_type": "text"
      },
      "source": [
        "### 2. Define a Convolution Neural Network\n",
        "Let's define a convolutional neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX24OzUnFMLG",
        "colab_type": "text"
      },
      "source": [
        "#### What is a convolution?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uI7GLeqJmTH",
        "colab_type": "text"
      },
      "source": [
        "You can think of it as a sliding window matrix multiplication.\n",
        "\n",
        "In the context of Neural Networks they allow to reduce the number of parameters in a layer (think how many weights do you need in a full connected neuron layer versus a convolution that maintain resolution among input and output), while preserving spatial locality.\n",
        "And depending on the parametrization we can achieve several results:\n",
        "\n",
        "3x3 kernel, no padding and no strides:\n",
        "\n",
        "![conv_nono](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif)\n",
        "\n",
        "3x3 kernel, same padding (half the size of the kernel) and no strides:\n",
        "\n",
        "![conv_halfno](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/same_padding_no_strides.gif)\n",
        "\n",
        "3x3 kernel, full padding and no strides:\n",
        "\n",
        "![conv_fullno](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/full_padding_no_strides.gif)\n",
        "\n",
        "3x3 kernel, same padding and strides:\n",
        "\n",
        "![conv_halfyes](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJrqaqfaJxO7",
        "colab_type": "text"
      },
      "source": [
        "#### MaxPooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3FEOCGfJtO4",
        "colab_type": "text"
      },
      "source": [
        "We want the network to learn the general concepts behind our images.\n",
        "\n",
        "We don't have to maintain the resolution of the image through all the network, we can downsample or upsample the image as needed per our requirements.\n",
        "\n",
        "The Convolution operation can already do that (depending on the parameters, we control the output size).\n",
        "\n",
        "Another way is through the Pooling operations, that can reduce the size of the input by applying some local operation like an average or a maximum.\n",
        "\n",
        "A maxpool will do something like this:\n",
        "![maxpool](http://cs231n.github.io/assets/cnn/maxpool.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH4CjfGkJ4xl",
        "colab_type": "text"
      },
      "source": [
        "#### Our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ-IPxLZec0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy_XKTCKec0Y",
        "colab_type": "text"
      },
      "source": [
        "### 3. Define a Loss function and optimizer\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykaOdKgKec0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuDrjRy0ec0b",
        "colab_type": "text"
      },
      "source": [
        "### 4. Train the network\n",
        "This is when things start to get interesting. \n",
        "To train the network we simply have to loop over our data iterator, and feed the inputs to the network and optimize.\n",
        "\n",
        "We can loop over the whole dataset multiple times, each iteration is called an epoch. Each set of images that we pass to the network at the same time is a batch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5i4-Ypyec0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 2\n",
        "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch+1}, {i+1 :5}] loss: {running_loss/2000 :.3}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSXuByKvec0g",
        "colab_type": "text"
      },
      "source": [
        "### 5. Test the network on the test data\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Let's see first an image from the test set to get familiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VI2SfaMec0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]}' for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q2xPdo9ec0p",
        "colab_type": "text"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bnjwQOCec0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = net(images.to(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iEHF-I3ec0y",
        "colab_type": "text"
      },
      "source": [
        "The outputs are energies/probabilities for the 10 classes.\n",
        "Higher the energy for a class, the more the network _thinks_ that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4gTuCOjec00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]}' for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03YZ9n2Eec07",
        "colab_type": "text"
      },
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "How does the network perform on the whole dataset?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb45O0o3ec08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp2Xg59mec0_",
        "colab_type": "text"
      },
      "source": [
        "That looks waaay better than chance, which is 10% accuracy (randomly picking a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "Finally, we can also check what are the classes that performed well, and the classes that did not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAqY-0zlec0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b3b06474-ee2b-455b-f2fa-a7965abfd50d"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print(f'Accuracy of {classes[i] : >10} : {100 * class_correct[i] / class_total[i] : 2}%')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of   airplane :  55.4%\n",
            "Accuracy of automobile :  80.8%\n",
            "Accuracy of       bird :  48.6%\n",
            "Accuracy of        cat :  46.5%\n",
            "Accuracy of       deer :  54.4%\n",
            "Accuracy of        dog :  46.8%\n",
            "Accuracy of       frog :  72.2%\n",
            "Accuracy of      horse :  70.6%\n",
            "Accuracy of       ship :  84.2%\n",
            "Accuracy of      truck :  72.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRG6qo1IIt_6",
        "colab_type": "text"
      },
      "source": [
        "## Where to now?\n",
        "\n",
        "Try to modify the network and see how your changes affect the results."
      ]
    }
  ]
}