{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dnn_pytorch_intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn52EGF8TxYF",
        "colab_type": "text"
      },
      "source": [
        "# (_Deep_) Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50V89jcwop1s",
        "colab_type": "text"
      },
      "source": [
        "## What is a Neural Network\n",
        "\n",
        "### Inspired by the the biological Neuron\n",
        "\n",
        "![Biological neuron](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Neuron.svg/1024px-Neuron.svg.png)\n",
        "\n",
        "### A Neuron (Perceptron) from a Neural Network\n",
        "\n",
        "![Perceptron](https://miro.medium.com/max/700/1*n6sJ4yZQzwKL9wnF5wnVNg.png)\n",
        "\n",
        "### If we stack multiple perceptrons in layers\n",
        "\n",
        "![multilayer perceptron](https://depthtest.github.io/content/neural_rsc/neural_net2.jpeg)\n",
        "\n",
        "If each neuron layer is represented by a function $f_i$ that operates on vectors, then the multilayer combination is a composition of functions $y=f_3(f_2(f_1(\\mathbf{x})))$, being $y$ the result of the feedforward network, and $\\mathbf{x}$ the input in vectorial notation.\n",
        "\n",
        "With multiple layers hidden, we now have a **Deep Neural Network**.\n",
        "\n",
        "## So, NNs are function approximators\n",
        "Through the composition of simple (non-linear) functions we can achieve arbitrarily complex functions\n",
        "\n",
        "**BUT**\n",
        "\n",
        "How do we define those functions?\n",
        "\n",
        "## Parameters\n",
        "By changing the weights. \n",
        "\n",
        "The weights in the neurons are the parameters to be learned during training because they mark the behaviour of the whole function defined by the network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdeE--zXvUe3",
        "colab_type": "text"
      },
      "source": [
        "## Training (through Gradient Descent)\n",
        "Ok, but how do we really train a neural network?\n",
        "\n",
        "First we need a measure of how good/bad the network is doing. This will be the loss function that we want to evaluate (more often than not, this will be based on a distance metric between the network result and the expected _true_ result, although it can be whatever metric you can think of)\n",
        "\n",
        "Now picture this (sample for 2 parameters; the more parameters you have, more dimensions you will have to work with):\n",
        "![Loss landscape](https://miro.medium.com/max/1400/0*KUao5zocCfeI_DuF.png)\n",
        "\n",
        "For each selection of weights the result of using the network with some training (test) data will provide a loss result. Graphing it, we have a landscape of the function loss. If the loss represents the error the network has, we want to **minimize** it!\n",
        "\n",
        "How to do that? Say hello to calculus.\n",
        "\n",
        "We have a measure of the rate of change / slope of the loss through the **derivative**. The derivative will tell us in which direction the loss changes most, so if we want to minimize the loss then we have to _move_ the weights in the negative direction of the derivative. \n",
        "\n",
        "That's what gradient descent is about, moving the weights in the negative direction of the derivative of the loss:\n",
        "$$\\mathbf{w_{k+1}}=\\mathbf{w_k}-\\lambda\\nabla Loss(\\mathbf{w_k})$$\n",
        "\n",
        "We don't now how much to move, so we use a learning rate, here $\\lambda$. This learning rate will be a hyperparameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fdrdq_5vaLs",
        "colab_type": "text"
      },
      "source": [
        "## Backpropagation\n",
        "That is fine and dandy, but how to do it to each and every neuron?\n",
        "After all, each neuron represents a whole (composited) function; do we have to do each derivative by hand?\n",
        "\n",
        "![Backpropagate](https://depthtest.github.io/content/neural_rsc/neural_net_backprop.jpeg)\n",
        "\n",
        "We will apply Calculus Chain Rule. Compute Loss and _PROPAGATE_ it _BACK_ through the network until arriving to the inputs, updating the weights on the way. \n",
        "\n",
        "Additionally, doing it this way allows two advantages:\n",
        "1.   Each neuron knows its mathematical function, so it knows its derivative\n",
        "2.   The same computation may be reused multiple times, saving computation time in exchange of memory.\n",
        "\n",
        "So, from the output layer:\n",
        "$$\\nabla Loss(\\mathbf{w}_H) = \\frac{\\partial Loss}{\\partial \\mathbf{w}_{Hb_i, H}}$$\n",
        "\n",
        "\n",
        "If we go to the second layer, the loss for each neuron:\n",
        "$$\\nabla Loss(\\mathbf{w}_{Hb_0}) = \\frac{\\partial Loss}{\\partial w_{Hb_0, H}} \\frac{\\partial w_{Hb_0, H}}{\\partial \\mathbf{w}_{Ha_i, Hb_0}}$$\n",
        "\n",
        "$$\\nabla Loss(\\mathbf{w}_{Hb_1}) = \\frac{\\partial Loss}{\\partial w_{Hb_1, H}} \\frac{\\partial w_{Hb_1, H}}{\\partial \\mathbf{w}_{Ha_i, Hb_1}}$$\n",
        "\n",
        "$$\\nabla Loss(\\mathbf{w}_{Hb_2}) = \\frac{\\partial Loss}{\\partial w_{Hb_2, H}} \\frac{\\partial w_{Hb_2, H}}{\\partial \\mathbf{w}_{Ha_i, Hb_2}}$$\n",
        "\n",
        "$$\\nabla Loss(\\mathbf{w}_{Hb_3}) = \\frac{\\partial Loss}{\\partial w_{Hb_3, H}} \\frac{\\partial w_{Hb_3, H}}{\\partial \\mathbf{w}_{Ha_i, Hb_3}}$$\n",
        "\n",
        "Then, to the first layer (shown here only the neuron $Ha_0$):\n",
        "$$\\begin{align}\n",
        "\\nabla Loss(\\mathbf{w}_{Ha_0}) = \n",
        "\\frac{\\partial }{\\partial \\mathbf{w}_{X_i,Ha_0}} & \\left(\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_0, H}} \\frac{\\partial w_{Hb_0, H}}{\\partial w_{Ha_0, Hb_0}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_1, H}} \\frac{\\partial w_{Hb_1, H}}{\\partial w_{Ha_0, Hb_1}} + \\frac{\\partial Loss}{\\partial w_{Hb_2, H}} \\frac{\\partial w_{Hb_2, H}}{\\partial w_{Ha_0, Hb_2}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_3, H}} \\frac{\\partial w_{Hb_3, H}}{\\partial w_{Ha_0, Hb_3}} \\right)\n",
        "\\end{align}$$\n",
        "\n",
        "\n",
        "We could check even how much depends the loss result on each of the inputs (here only shown for $X_0$):\n",
        "$$\\begin{align}\n",
        "\\nabla Loss(X_0) = \\frac{\\partial }{\\partial X_0} & \\Bigg( \\\\\n",
        "\\frac{\\partial }{\\partial \\mathbf{w}_{X_i,Ha_0}} & \\left(\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_0, H}} \\frac{\\partial w_{Hb_0, H}}{\\partial w_{Ha_0, Hb_0}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_1, H}} \\frac{\\partial w_{Hb_1, H}}{\\partial w_{Ha_0, Hb_1}} +\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_2, H}} \\frac{\\partial w_{Hb_2, H}}{\\partial w_{Ha_0, Hb_2}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_3, H}} \\frac{\\partial w_{Hb_3, H}}{\\partial w_{Ha_0, Hb_3}} \\right) + \\\\\n",
        "\\frac{\\partial }{\\partial \\mathbf{w}_{X_i,Ha_1}} & \\left(\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_0, H}} \\frac{\\partial w_{Hb_0, H}}{\\partial w_{Ha_1, Hb_0}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_1, H}} \\frac{\\partial w_{Hb_1, H}}{\\partial w_{Ha_1, Hb_1}} +\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_2, H}} \\frac{\\partial w_{Hb_2, H}}{\\partial w_{Ha_1, Hb_2}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_3, H}} \\frac{\\partial w_{Hb_3, H}}{\\partial w_{Ha_1, Hb_3}} \\right) + \\\\\n",
        "\\frac{\\partial }{\\partial \\mathbf{w}_{X_i,Ha_2}} & \\left(\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_0, H}} \\frac{\\partial w_{Hb_0, H}}{\\partial w_{Ha_2, Hb_0}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_1, H}} \\frac{\\partial w_{Hb_1, H}}{\\partial w_{Ha_2, Hb_1}} +\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_2, H}} \\frac{\\partial w_{Hb_2, H}}{\\partial w_{Ha_2, Hb_2}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_3, H}} \\frac{\\partial w_{Hb_3, H}}{\\partial w_{Ha_2, Hb_3}} \\right) + \\\\\n",
        "\\frac{\\partial }{\\partial \\mathbf{w}_{X_i,Ha_3}} & \\left(\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_0, H}} \\frac{\\partial w_{Hb_0, H}}{\\partial w_{Ha_3, Hb_0}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_1, H}} \\frac{\\partial w_{Hb_1, H}}{\\partial w_{Ha_3, Hb_1}} +\n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_2, H}} \\frac{\\partial w_{Hb_2, H}}{\\partial w_{Ha_3, Hb_2}} + \n",
        "\\frac{\\partial Loss}{\\partial w_{Hb_3, H}} \\frac{\\partial w_{Hb_3, H}}{\\partial w_{Ha_3, Hb_3}} \\right)\n",
        "\\Bigg)\n",
        "\\end{align}$$\n",
        "\n",
        "# Thankfully all this is taken care of by libraries like PyTorch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPJXz7cThCjG",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch\n",
        "\n",
        "Important: https://pytorch.org/docs/stable/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq9JTMmeV7ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fun\n",
        "import torch.optim as optim\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SExNkRadgxOi",
        "colab_type": "text"
      },
      "source": [
        "## Using Tensors in PyTorch\n",
        "(they are conceptually the _same_ as numpy arrays)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HYt14S9WBhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy\n",
        "import numpy as np\n",
        "from numpy.linalg import inv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xCNkz8okdN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy\n",
        "np.eye(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY3KmIWhkpcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch\n",
        "torch.eye(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zDpO4-nkZjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy\n",
        "X = np.random.random((5, 3))\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ8xyKKhksLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch\n",
        "Y = torch.rand((5, 3))\n",
        "Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx6GjI22khh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy\n",
        "X.T @ X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-hoQohtk1Hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch\n",
        "Y.t() @ Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eN3K78mkjJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy\n",
        "inv(X.T @ X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrFCshXsk3sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch\n",
        "torch.inverse(Y.t() @ Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a4PunkYlMg5",
        "colab_type": "text"
      },
      "source": [
        "## More on Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gstE07TFlH_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.eye(3)\n",
        "A.add(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z9UawQJlKgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A[0, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx3R-oZRlLzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A[:, 1:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9vIWCb0lD6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch --> numpy\n",
        "B = A.numpy()\n",
        "B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhcE6JKplTsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy --> torch\n",
        "torch.from_numpy(np.eye(3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6FQYLHVlYpP",
        "colab_type": "text"
      },
      "source": [
        "## Using the GPU\n",
        "Here in Colab you will need a GPU-based environment. Go to `Runtime -> Change runtime type -> Hardware accelerator` and select GPU.\n",
        "\n",
        "TPU is for Tensorflow for now, although there is work being done for PyTorch to be compatible with TPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0a6G6XxlXrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking if device is available and selecting it\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaNUuu10lkuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating data and moving to device\n",
        "data = torch.eye(3).to(device)\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXbx9Fovlmn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computation is now done on device\n",
        "res = data + data\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sw-CfvKs_ct",
        "colab_type": "text"
      },
      "source": [
        "## Automatic differentiation with _autograd_\n",
        "\n",
        "Tensor can record gradients directly if you tell it do do so, e.g. torch.ones(3, requires_grad=True). Prior to `v0.4` it had to be done with the `Variable` class, there is no need for Variable anymore. Many tutorials still use Variable, be aware!\n",
        "\n",
        "Related: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "\n",
        "You rarely use `torch.autograd` directly. Pretty much everything is part or `torch.Tensor` now. Simply add `requires_grad=True` to the tensors you want to calculate the gradients for. `nn.Module` track gradients automatically (they will define the lego pieces with which to build the networks)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUdFCOgiv0DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import autograd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0UQSJlMv3IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor(2.)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsFpoDTQv4SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor(2., requires_grad=True)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vyyFHUPv9rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16jkI3TtwBON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x ** 2\n",
        "\n",
        "print(\"Grad of x:\", x.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd-D9tclwGnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x ** 2\n",
        "y.backward()\n",
        "\n",
        "print(\"Grad of x:\", x.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvIGxilRwMc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't record the gradient\n",
        "# Useful for inference\n",
        "\n",
        "params = torch.tensor(2., requires_grad=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = x * x\n",
        "    print(x.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6wU2MHYuuSP",
        "colab_type": "text"
      },
      "source": [
        "## Let's try a linear regression with Gradient Descent in PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq-v8chQipEo",
        "colab_type": "text"
      },
      "source": [
        "### Getting the California Housing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsQnUWe2zOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "housing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvHkNam95UoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples, n_features = housing.data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF3dpcDNixTa",
        "colab_type": "text"
      },
      "source": [
        "### Getting the device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6iPG7ZU4ROz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXZAA2CQi3Wa",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Tensors from the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CAGxqCS3rb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.from_numpy(housing.data).float().to(device)\n",
        "y = torch.from_numpy(housing.target.reshape(-1,1)).float().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE8YRrapi75U",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Module to compute the Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KjHyjZ44iRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinReg(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.beta = nn.Linear(input_dim, 1, bias=True)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.beta(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTVDChkfjEpB",
        "colab_type": "text"
      },
      "source": [
        "### We create the Model, Criterion and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynE0YNjK4oy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LinReg(n_features).to(device)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyNLXHIcjKFZ",
        "colab_type": "text"
      },
      "source": [
        "### A train step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsc5NqnJ45x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train step\n",
        "model.train()  # <-- here\n",
        "optimizer.zero_grad()\n",
        "\n",
        "y_ = model(X)\n",
        "loss = loss_fn(y_, y)\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5HtT4sqj0-I",
        "colab_type": "text"
      },
      "source": [
        "Take into account two things:\n",
        "1.   We have not divided the dataset into train and test, which should be a must.\n",
        "2.   This is only a step in the optimization, we should create a loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBbZWHapjViP",
        "colab_type": "text"
      },
      "source": [
        "### In order to make inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2tyqM1rgTys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eval\n",
        "model.eval()  # <-- here\n",
        "with torch.no_grad():\n",
        "    y_ = model(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOO3F2qamXRe",
        "colab_type": "text"
      },
      "source": [
        "## Other nice things"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTpKajSKmbl8",
        "colab_type": "text"
      },
      "source": [
        "### Debugging\n",
        "\n",
        "You can use the Python Debugger (here the IPython Debugger)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmx8wpGBnMDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyd8xGFPnQGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_function(x):\n",
        "    answer = 42\n",
        "    set_trace()\n",
        "    answer += x\n",
        "    return answer\n",
        "\n",
        "my_function(12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5yuJwUTnZjb",
        "colab_type": "text"
      },
      "source": [
        "#### Let's revisit the Linear Regression Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD87BPKanddl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinRegBreak(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.beta = nn.Linear(input_dim, 1, bias=True)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        set_trace()\n",
        "        return self.beta(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWnQw0slnyvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LinRegBreak(n_features).to(device)\n",
        "\n",
        "# For testing purposes, execute just in inference mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_ = model(X)\n",
        "y_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5jjXK46mg2s",
        "colab_type": "text"
      },
      "source": [
        "### Saving and restoring models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MyG-n0qpXD-",
        "colab_type": "text"
      },
      "source": [
        "#### nn.Module.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMeESnY-p_Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LinReg(n_features)\n",
        "model.state_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1ZakNktpe8u",
        "colab_type": "text"
      },
      "source": [
        "#### nn.Optimizer.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfwFCkG4qFmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "optimizer.state_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl9Z7rzZpjTs",
        "colab_type": "text"
      },
      "source": [
        "#### Storing and loading `state_dict`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nypGhkhqMCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = \"model_state_dict.pt\"\n",
        "torch.save(model.state_dict(), model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS1uxSK_qQWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LinReg(n_features)\n",
        "model.load_state_dict(torch.load(model_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zD7W1akkpyki"
      },
      "source": [
        "#### Storing and loading full_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0PFTaKrrGq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = \"model_123.pt\"\n",
        "torch.save(model, model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K-725A0rHJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only works if code for `LinReg` module is available right now\n",
        "model = torch.load(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bGLQdaZ4py0h"
      },
      "source": [
        "#### Sample Checkpointing\n",
        "You can store model, optimizer and arbitrary information and reload it.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "torch.save(\n",
        "    {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'loss': loss,\n",
        "    },\n",
        "    PATH,\n",
        ")\n",
        "```"
      ]
    }
  ]
}